---
title: "project"
author: "Yilin Gao"
date: "May 6, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages}
library(dplyr)
library(corrplot)
library(forcats)
library(randomForest)
library(gbm)
```

## Load and clean data

```{r load data, echo=FALSE}
load("ames_train.Rdata")
load("ames_test.Rdata")
load("ames_validation.Rdata")
```

```{r data cleaing}
train = ames_train %>% 
  mutate(datset = "train")
test = ames_test %>%
  mutate(datset = "test")
valid = ames_validation %>%
  mutate(datset = "valid")

dat = train %>% 
  rbind(., test) %>%
  rbind(., valid)

findNA = function(col){
  numNA = sum(is.na(col) | col == "")
  type = class(col)
  level = paste(as.character(levels(col)), collapse = ";")
  large_0 = sum(table(col) > 0)
  return(c(numNA, type, level, large_0))
}

train_info = lapply(dat, findNA)
train_info = as.data.frame(do.call(rbind, train_info), stringsAsFactors = F)
colnames(train_info) = c("numNA", "class", "level")
train_info$numNA = as.numeric(train_info$numNA)
train_info$missing_ratio = train_info$numNA/nrow(ames_train)
train_info$names = rownames(train_info)


dat1 = dat

# Bsmt.Exposure
dat1$Bsmt.Exposure[dat1$Bsmt.Exposure == "" &
                     !is.na(dat1$Bsmt.Exposure)] = names(sort(table(dat1$Bsmt.Exposure), 
                                                              decreasing = T))[1]
dat1$Mas.Vnr.Type[dat1$Mas.Vnr.Type == ""] = "None"
dat1$Electrical[dat1$Electrical == ""] = names(sort(table(dat1$Electrical),
                                                    decreasing = T))[1]
dat1$BsmtFin.Type.2[dat1$BsmtFin.Type.2 == "" &
                      !is.na(dat1$BsmtFin.Type.2)] = NA

dat2 = dat1 %>%
  dplyr::select(-Garage.Yr.Blt) %>%
  filter(PID != 903426160) %>%
  mutate(MS.SubClass = as.factor(MS.SubClass),
         Lot.Frontage = ifelse(is.na(Lot.Frontage), 0, Lot.Frontage),
         Alley = fct_explicit_na(Alley, "Unknown"),
         Pool.QC = fct_explicit_na(Pool.QC, "Unknown"),
         Pool.QC = as.numeric(factor(Pool.QC,
                                     levels = c("Unknown", "Fa", 
                                                    "TA", "Gd", "Ex"))),
         Fence = fct_explicit_na(Fence, "Unknown"),
         Fence = as.numeric(factor(Fence,
                                     levels = c("Unknown", "MnWw", "GdWo", 
                                                    "MnPrv", "GdPrv"))),
         Misc.Feature = fct_explicit_na(Misc.Feature, "Unknown"),
         Fireplace.Qu = fct_explicit_na(Fireplace.Qu, "Unknown"),
         Fireplace.Qu = as.numeric(factor(Fireplace.Qu,
                                          levels = c("Unknown", "Po", "Fa",
                                                     "TA", "Gd", "Ex"))),
         Garage.Cond = fct_explicit_na(Garage.Cond, "Unknown"),
         Garage.Cond = as.numeric(factor(Garage.Cond, 
                                         levels = c("Unknown", "Po", "Fa", 
                                                    "TA", "Gd", "Ex"))),
         Garage.Qual = fct_explicit_na(Garage.Qual, "Unknown"),
         Garage.Qual = as.numeric(factor(Garage.Qual, 
                                         levels = c("Unknown", "Po", "Fa", 
                                                    "TA", "Gd", "Ex"))),
         Garage.Type = fct_explicit_na(Garage.Type, "Unknown"),
         Garage.Finish = fct_explicit_na(Garage.Finish, "Unknown"),
         Garage.Finish = as.numeric(factor(Garage.Finish, 
                                           levels = c("Unknown", "Unf", 
                                                      "RFn", "Fin"))),
         Bsmt.Qual = fct_explicit_na(Bsmt.Qual, "Unknown"),
         Bsmt.Qual = as.numeric(factor(Bsmt.Qual, 
                                       levels = c("Unknown", "Po", "Fa", 
                                                  "TA", "Gd", "Ex"))),
         Bsmt.Cond = fct_explicit_na(Bsmt.Cond, "Unknown"),
         Bsmt.Cond = as.numeric(factor(Bsmt.Cond, 
                                       levels = c("Unknown", "Po", "Fa", 
                                                  "TA", "Gd", "Ex"))),
         Bsmt.Exposure = fct_explicit_na(Bsmt.Exposure, "Unknown"),
         Bsmt.Exposure = as.numeric(factor(Bsmt.Exposure, 
                                           levels = c("Unknown", "No", "Mn", 
                                                      "Av", "Gd"))),
         BsmtFin.Type.1 = fct_explicit_na(BsmtFin.Type.1, "Unknown"),
         BsmtFin.Type.1 = as.numeric(factor(BsmtFin.Type.1, 
                                            levels = c("Unknown", "Unf","LwQ",
                                                       "Rec", "BLQ", 
                                                       "ALQ", "GLQ"))),
         BsmtFin.Type.2 = fct_explicit_na(BsmtFin.Type.2, "Unknown"),
         BsmtFin.Type.2 = as.numeric(factor(BsmtFin.Type.2, 
                                            levels = c("Unknown", "Unf","LwQ",
                                                       "Rec", "BLQ", 
                                                       "ALQ", "GLQ"))),
         Mas.Vnr.Area = ifelse(is.na(Mas.Vnr.Area), 0, Mas.Vnr.Area),
         Utilities = as.numeric(factor(Utilities, 
                                       levels = c("ELO","NoSeWa","NoSewr","AllPub"))),
         Lot.Shape = as.numeric(factor(Lot.Shape, 
                                       levels = c("IR3","IR2","IR1","Reg"))),
         Exter.Qual= as.numeric(factor(Exter.Qual, 
                                       levels = c("Po", "Fa", 
                                                  "TA", "Gd", "Ex"))),
         Land.Slope =  as.numeric(factor(Land.Slope, 
                                         levels = c("Sev", "Mod","Gtl"))),
         Exter.Cond = as.numeric(factor(Exter.Cond, 
                                        levels = c("Po", "Fa", 
                                                   "TA", "Gd", "Ex"))),
         Heating.QC = as.numeric(factor(Heating.QC, 
                                        levels = c("Po", "Fa", 
                                                   "TA", "Gd", "Ex"))),
         Electrical = as.numeric(factor(Electrical, 
                                        levels = c("Mix", "FuseP", 
                                                   "FuseF", "FuseA", "SBrkr"))),
         Kitchen.Qual = as.numeric(factor(Kitchen.Qual, 
                                          levels = c("Po", "Fa", 
                                                     "TA", "Gd", "Ex"))),
         Functional = as.numeric(factor(Functional, 
                                        levels = c("Sal", "Sev", 
                                                   "Maj2", "Maj1", "Mod",
                                                   "Min2","Min1","Typ"))),
         Paved.Drive = as.numeric(factor(Paved.Drive, 
                                         levels = c("N", "P","Y"))),
         Bsmt.Half.Bath = ifelse(is.na(Bsmt.Half.Bath), 0, Lot.Frontage),
         Bsmt.Full.Bath = ifelse(is.na(Bsmt.Full.Bath), 0, Lot.Frontage)
  )

dat3 = dat2 %>%
  dplyr::select(-Condition.2)  # different levels in training and testing data

train_clean = dat3[dat3$datset == "train",] %>%
  dplyr::select(-datset)
test_clean = dat3[dat3$datset == "test",] %>%
  dplyr::select(-datset)
validation_clean = dat3[dat3$datset == "valid",] %>%
  dplyr::select(-datset)
```

```{r functions, echo=FALSE}
check = function(pred, true_value){
  return(data.frame(RMSE = RMSE(pred[,1],true_value),
                    BIAS = BIAS(pred[,1],true_value),
                    maxDeviation = maxDeviation(pred[,1],true_value),
                    MeanAbsDeviation = MeanAbsDeviation(pred[,1],true_value),
                    Coverage = coverage(pred[,2], pred[,3], true_value)))
}
RMSE = function(y,pred) {
  rmse = sqrt(mean((y-pred)^2))
  return(rmse)
}

BIAS = function(pred, true_value){
  return(mean(pred-true_value))
}
maxDeviation = function(pred, true_value){
  return(max(abs(pred-true_value)))
}
MeanAbsDeviation = function(pred, true_value){
  return(mean(abs(pred-true_value)))
}
coverage = function(lwr,upr,true_value){
  mean(lwr<true_value & true_value<upr)
}
```

## Data Description plots

```{r distribution of price, echo=FALSE}
png(width=900, pointsize=15, filename = "price.png")
par(mfrow = c(1,2))
hist(train_clean$price, breaks = 30)
hist(log(train_clean$price), breaks = 30)
```

```{r correlation between variables, echo=FALSE}
isNums = sapply(train_clean, is.numeric)
M = cor(train_clean[, isNums])
png(height=1200, width=1500, pointsize=15, filename = "corr.png")
corrplot(M, method="circle", insig = "blank", tl.cex = 1/par("cex"),
    cl.cex = 1/par("cex"), addCoefasPercent = TRUE)
```

```{r facet plot of Neighborhood, echo=FALSE}
library(ggplot2)
png(height=600, width=1000, filename = "facet.png")
ggplot(data = train_clean, aes(x = area, y = price)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~ Neighborhood)
```

```{r variable importance, echo=FALSE}
model_rf = randomForest(log(price) ~., data = train_clean, mtry = 9, importance = T)
png(width=900, pointsize=15, filename = "rf_varImportance.png")
varImpPlot(model_rf)

model_boosting = gbm(log(price) ~., data = train_clean, distribution = "gaussian", n.trees = 30000,
                     interaction.depth = 4)
png(pointsize=15, filename = "boosting_varImportance.png")
summary(model_boosting)
```

## Fitting Models

1. OLS and BIC stepwise variable selection

```{r ols with BIC}
# ols
model_ols = lm(log(price) ~ . , 
               data = train_clean[-c(168,183,462),])
summary(model_ols)

# ols with BIC stepwise variable selection
model_ols_bic = step(model_ols, k = log(nrow(train_clean)), trace = F)
summary(model_ols_bic)

# rmse of training data
predict_ols_bic_train = exp(model_ols_bic$fitted.values)
rmse_ols_bic_train = RMSE(predict_ols_bic_train, train_clean[-c(168,183,462),]$price)

# rmse and other statistics of testing data
predict_ols_bic_test = predict(model_ols_bic, newdata = test_clean, interval = "predict")
predict_ols_bic_test = exp(predict_ols_bic_test)
rmse_ols_bic_test = RMSE(predict_ols_bic_test[1,], test_clean$price)
check(predict_ols_bic_test, test_clean$price)
# plot of prediction value and actual value of testing data
plot(test_clean$price, predict_ols_bic_test[,1], )
abline(a=0, b=1)

# diagnostic plots of the BIC model
par(mfrow=c(2,2))
plot(model_ols_bic)
# look at term plots of the BIC model for variable transformation
par(mfrow=c(2,2))
termplot(model = model_ols_bic, partial.resid = T, se = T, rug = T, smooth = panel.smooth)
```

2. variable transformation based on BIC stepwise variable selection

```{r ols trans x and y}
model_ols_trans = lm(log(price) ~ 
                       area + log(Lot.Area + 1) + Neighborhood + Bldg.Type + 
                       Overall.Qual + Overall.Cond + 
                       Year.Built + 
                       # Year.Remod.Add + 
                       Bsmt.Exposure + BsmtFin.SF.1 + BsmtFin.SF.2 + Bsmt.Unf.SF +
                       Central.Air + 
                       Kitchen.Qual + Functional + 
                       Fireplaces + 
                       Garage.Cars + 
                       # Garage.Area + 
                       Paved.Drive + Open.Porch.SF, 
                       #+ log(Enclosed.Porch + 1) + log(Screen.Porch + 1), 
                       data = train_clean[-c(168,183,462),])
par(mfrow=c(2,2))
plot(model_ols_trans)

# RMSE on training data
predict_ols_trans_train = exp(model_ols_trans$fitted.values)
rmse_ols_trans_train = RMSE(predict_ols_trans_train, train_clean[-c(168,183,462),]$price)

# rmse and other statistics on testing data
predict_ols_trans_test = predict(model_ols_trans, newdata = test_clean, interval = "predict")
predict_ols_trans_test = exp(predict_ols_trans_test)
rmse_ols_trans_test = RMSE(predict_ols_trans_test[1,], test_clean$price)
check(predict_ols_trans_test, test_clean$price)
# plot of prediction value and actual value of testing data
plot(test_clean$price, predict_ols_trans_test[,1] )
abline(a=0, b=1)
# diagnostic plots
par(mfrow=c(2,2))
plot(model_ols_trans)
# termplot(model = model_ols_trans, partial.resid = T, se = T, rug = T, smooth = panel.smooth)
```

3. poisson regression

```{r poisson}
library(MASS)

#delete columns with colinearity and new levels
delete_list = c(16,74,46,48,39,23,24,25)

model_poi =glm(price ~ .-PID, 
              data = train_clean[,-delete_list],family="poisson")

model_poi_bic = step(model_poi, k = log(nrow(train_clean)),trace = F)

predict_poi_train = predict(model_poi_bic, newdata = train_clean)
predict_poi_train = exp(predict_poi_train)
rmse_poi_train = RMSE(predict_poi_train, train_clean$price)
rmse_poi_train

predict_poi_test = predict(model_poi_bic, newdata = test_clean)
predict_poi_test = exp(predict_poi_test)
rmse_poi_test = RMSE(predict_poi_test, test_clean$price)
rmse_poi_test
```

4. boosting

```{r boosting}
library(gbm)
model_boosting = gbm(exp(price) ~ area + log(Lot.Area + 1) + Neighborhood + Bldg.Type + Overall.Qual +
                       Overall.Cond + Year.Built + 
                       #Year.Remod.Add + 
                       Bsmt.Exposure + BsmtFin.SF.1 + 
                       BsmtFin.SF.2 + Bsmt.Unf.SF + Central.Air + Kitchen.Qual + Functional + 
                       Fireplaces + Garage.Cars + Garage.Area + Paved.Drive + Open.Porch.SF ,
                       #log(Enclosed.Porch + 1) + log(Screen.Porch + 1), , 
                     data = train_clean[-c(168,183,462),], 
                     distribution = "gaussian",
                     n.trees = 30000, 
                     interaction.depth = 4)
summary(model_boosting, plotit = F)

predict_boosting_test = predict(model_boosting, newdata = test_clean, n.trees = 30000)
predict_boosting_test = exp(predict_boosting_test)
# how to compute prediction intervals for boosting?
rmse_boosting_test = RMSE(predict_boosting_test, test_clean$price)
rmse_boosting_test
# plot of true price and predicted preice
plot(test_clean$price, predict_boosting_test)
abline(a=0, b=1)
```

5. random forest

```{r random forest}
library(randomForest)
model_rf = randomForest(log(price) ~ ., 
                        data = train_clean,
                        mtry = sqrt(ncol(train_clean)),
                        importance = T)
# plot of random forest
summary(model_rf)
model_rf
# rmse of training data
predict_rf_train = predict(model_rf)
predict_rf_train = exp(predict_rf_train)
rmse_rf_train = RMSE(predict_rf_train, train_clean$price)
rmse_rf_train
# rmse of testing data
predict_rf_test = predict(model_rf, newdata = test_clean)
predict_rf_test = exp(predict_rf_test)
rmse_rf_test = RMSE(predict_rf_test, test_clean$price)
rmse_rf_test
```

6. lasso

```{r process variables and get the model}
suppressMessages(library(MASS))
suppressMessages(library(knitr))

set.seed(1)
delete_list = c(23,24,25,39,44,45,46)

cont_var = setdiff(names(sapply(train_clean[,-delete_list],class))[sapply(train_clean[,-delete_list],class)!="factor"],c("PID","price"))
factor_var = names(sapply(train_clean[,-delete_list],class))[sapply(train_clean[,-delete_list],class)=="factor"]

interac = paste("area",paste(":",factor_var))
# formula for lasso
fmla = as.formula(paste("log(price) ~ Neighborhood:area+", paste(cont_var, collapse= "+"),"+",paste(factor_var,collapse = "+"),"+",paste(interac,collapse = "+")))

suppressMessages(library(glmnet))

# use cross validation to choose the best lambda
model_lasso = cv.glmnet(model.matrix(fmla,train_clean)[,-1], 
                      log(train_clean$price), 
                      alpha=1,
                      lambda= 10^seq(4,-3,length= 1000))
model_lasso.lambda.best = model_lasso$lambda.min

tmp_coeffs <- coef(model_lasso, s = "lambda.min")
df = data.frame(name = tmp_coeffs@Dimnames[[1]][tmp_coeffs@i+1], coefficient = tmp_coeffs@x)
kable(df)
```

```{r prediction on train data}
predict_lasso_train = predict(model_lasso, 
                      model.matrix(fmla, train_clean)[,-1],
                      s = model_lasso.lambda.best)
predict_lasso_train = exp(predict_lasso_train)
rmse_lasso_train = RMSE(predict_lasso_train, train_clean$price)
rmse_lasso_train
```

```{r prediction on test data}
predict_lasso_test = predict(model_lasso, 
                      model.matrix(fmla,test_clean)[,-1],
                      s = model_lasso.lambda.best)
predict_lasso_test = exp(predict_lasso_test)
rmse_lasso_test = RMSE(predict_lasso_test, test_clean$price)
rmse_lasso_test
```

```{r confidence interval on test data}
nsim = 50
predict_lasso_test_multiple = matrix(0, nrow(test_clean), nsim)

for(i in 1:nsim){
  model_lasso_temp = cv.glmnet(model.matrix(fmla,train_clean)[,-1],
                      log(train_clean$price),
                      alpha=1,
                      lambda= 10^seq(4,-3,length= 1000))
  model_lasso_temp.lambda.best = model_lasso_temp$lambda.min

  predict_lassp_temp = predict(model_lasso_temp,
                      model.matrix(fmla,test_clean)[,-1],
                      s = model_lasso_temp.lambda.best)
  predict_lasso_test_multiple[,i] = predict_lassp_temp
}

quantile_lasso_test = apply(exp(predict_lasso_test_multiple), 1, quantile, c(0.025,0.975))

coverage_lasso = coverage(quantile_lasso_test[1,], quantile_lasso_test[2,], test_clean$price)
coverage_lasso
```

## Summary of RMSE

```{r RMSE summary}
suppressMessages(library(xtable))
results = data.frame(OLSBIC = c(rmse_ols_bic_train, rmse_ols_bic_test),
                     OLSBICTRANS = c(rmse_ols_trans_train, rmse_ols_trans_test),
                     Poisson = c(rmse_poi_train, rmse_poi_test),
                     Boosting = c("-", rmse_boosting_test),
                     RandomForest = c(rmse_rf_train, rmse_rf_test),
                     LASSO = c(rmse_lasso_train, rmse_lasso_test))
rownames(results) = c("RMSE_train", "RMSE_test")
kable(results, digits = 2)
```

## RMSE of final model on validation data

```{r}
suppressMessages(library(dplyr))

download.file("http://www.openintro.org/stat/data/ames.RData", destfile = "ames.RData")
load("ames.RData")

ames_validation2 = left_join(ames_validation,ames[,c("PID","SalePrice")],by="PID")
ames_validation2 = ames_validation2[,-3]
```

```{r}
validation_clean$price = ames_validation2$SalePrice
predict_lasso_validation = predict(model2, 
                      model.matrix(fmla,validation_clean)[,-1],
                      s = model_lasso.lambda.best)
predict_lasso_validation = exp(predict_lasso_validation)
rmse_lasso_validation = RMSE(predict_lasso_validation, validation_clean$price)
```
