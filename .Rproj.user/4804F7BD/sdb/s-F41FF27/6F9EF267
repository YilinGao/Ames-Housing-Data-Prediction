{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Final Data Analysis Project\"\ndate:  \"Write up due April 28 at 5 pm\"\noutput: html_notebook\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n\nFor this project you will take the role of a consultant hired by a real estate investment firm in Ames, Iowa, a mid-west town in the United States, to analyze data in order to help provide insight into how the firm should invest for highest profits, and to quantify and communicate to the company management what types of real estate properties are good investments and why. They have provided you with data on housing sales from between 2006 to 2010 that contains information about the characteristics of the house (number of bedrooms, number of bathrooms, square footage, etc.) and the house's sale price. The codebook for this data set is [available online here ](https://ww2.amstat.org/publications/jse/v19n3/decock/datadocumentation.txt)  or in the Data folder in your repo.\n\n## About the Data Analysis Project\n\nIt's generally a bad idea to buy the most expensive house in the neighborhood. And remember the real estate agents' mantra: Location, location, location! Keep in mind that the goal is to make money for your investors, and hence investing in a property that is overvalued (costing more than it is worth) is rarely a good idea. This means that it's critical to know which properties are overvalued and which are undervalued.  The company that hired you has many questions for you about the housing market. It is up to you to decide what methods you want to use (frequentist or Bayesian) to answer these questions, and implement them to help to identify undervalued and overvalued properties.\n\n\nYou will have three data sets: a subset for training, a subset for testing, and a third subset for validation. You will be asked to do data exploration and build your model (or models) initially using only the training data. Then, you will test your model on the testing data, and finally validate using the validation data. We are challenging you to keep your analysis experience realistic, and in a realistic scenario you would not have access to all three of these data sets at once.  You will be able to see on our scoreboard how well your team is doing based on its predictive performance on the testing data.  After your project is turned in you will see the final score on the validation set.\n\nAll members of the team should contribute equally and answer any questions about the analysis at the final presentation.\n\nFor your analysis create a new notebook named \"project.Rmd\"\nand update accordingly rather than editing this.\n\n\n### Read in Training Data\n\nTo get started read in the training data:\n```{r read-data}\nload(\"ames_train.Rdata\")\n```\n\nThe `Neighborhood` variable, typically of little interest other than to model the location effect, may be of more relevance when used with the [map](http://www.amstat.org/publications/jse/v19n3/decock/AmesResidential.pdf).\n\nWe are restricting attention to just the \"normal sales\" condition.\n\n## Part I: Simple Model\n\nIn the first model you are allowed only limited manipulations of the original data set to predict the sales price `price`. You are allowed to take power transformations of the original variables [square roots, logs, inverses, squares, etc.] but you are NOT allowed to create interaction variables. This means that a variable may only be used once in an equation [if you use $ x^2$ don’t use $x$]. Additionally, you may eliminate any data points you deem unfit. This model should have a minimum r-square of 73% (in the original units) and contain at least 6 variables but fewer than 20.   \n\n```{r model1}\nmodel1 = lm(price ~ 1, data=ames_train)\n```\n\n\n\n### Model Evaluation on Test Data\nCreate predicted values for price using your model using the testing data\n\n```{r read-test-data}\nload(\"ames_test.Rdata\")\n```\n\n```{r predict-model1, echo=FALSE}\nYhat = predict(model1, newdata=ames_test, interval = \"pred\")\n```\n\nYou should save your predictions in a dataframe with columns for `PID`  (property identifier), `fit`, predicted values on the test data, and where possible `lwr` and `upr`, lower and upper 95% interval estimates for predicting `price`. \n\n```{r create }\n# name dataframe as predictions! DO NOT CHANGE\npredictions = as.data.frame(Yhat)\npredictions$PID = ames_test$PID\nsave(predictions, file=\"predict.Rdata\")\n```\n\nYour models will be evaluated on the following criteria on the test data: \n\n* Bias:  Average (Yhat-Y)  positive values indicate the model tends to overestimate price (on average) while negative values indicate the model tends to underestimate price.\n\n* Maximum Deviation:  Max |Y-Yhat| -  identifies the worst prediction  made in the validation data set.\n\n* Mean Absolute Deviation:  Average |Y-Yhat| - the average error (regardless of sign).\n\n* Root Mean Square Error: Sqrt Average (Y-Yhat)^2\n\n* Coverage:  Average( lwr < Y < upr) \n\nIn order to have a passing wercker badge, your file for predictions needs to be the same length as the test data, with three columns:  fitted values, lower CI and upper CI values in that order with names, fit, lwr, and upr respectively.  \n\nYou will be able to see your scores on the score board (coming soon!).  They will be initialized by a predction based on the mean in the training data.\n\n_Model Check_ - Test your prediction on the first observation in the training and test data set to make sure that the model gives a reasonable answer and include this in a supplement of your report. This should be done BY HAND using a calculator (this means use the raw data from the original dataset and manually calculate all transformations and interactions with your calculator)! Models that do not give reasonable answers will be given a minimum 2 letter grade reduction. Also be careful as you cannot use certain transformations [log or inverse x] if a variable has values of 0.\n\n### Part II: Complex Model\n\nIn this part you may go all out for constructing a best fitting model for predicting housing prices using methods that we have covered this semester.  You should feel free to to create any new variables (such as quadratic, interaction, or indicator variables, splines, etc). The variable `TotalSq = X1st.Flr.SF+X2nd.Flr.SF` was added to the dataframe (that does not include basement area, so you may improve on this. A relative grade is assigned by comparing your fit on the test set to that of your fellow students with bonus points awarded to those who substantially exceed their fellow students and point reductions occurring for models which fit exceedingly poorly.  \n\nUpdate your predictions using your complex model to provide point estimates and CI.\n\n```{r predict-model2, echo=FALSE}\n# replace model1 with model2\npredictions = as.data.frame(predict(model1, newdata=ames_test, interval = \"pred\"))\npredictions$PID = ames_test$PID\nsave(predictions, file=\"predict.Rdata\")\n```\n\nYou may iterate here as much as you like exploring different models until you are satisfied with your results.\n\n### Part III: Write Up\n\nOnce you are satisfied with your model, provide a write up of your data analysis project in a new Rmd file/pdf file: `writeup.Rmd` by copying over salient parts of your R notebook. The written assignment consists of five parts:\n\n1. Exploratory data analysis (20 points): must include three correctly labeled graphs and an explanation that highlight the most important features that went into your model building.\n\n2. Development and assessment of an initial model from Part I (10 points)\n\n* Initial model: must include a summary table and an explanation/discussion for variable selection.  Interpretation of coefficients desirable for full points.\n\n* Model selection: must include a discussion\n\n* Residual: must include a residual plot and a discussion\n\n* RMSE: must include an RMSE and an explanation  (other criteria desirable)\n\n* Model testing: must include an explanation\n\n3. Development of the final model (20 points)\n\n* Final model: must include a summary table\n\n* Variables: must include an explanation\n\n* Variable selection/shrinkage: must use appropriate method and include an explanation\n\n\n\n4. Assessment of the final model (25 points)\n\n* Residual: must include a residual plot and a discussion\n\n* RMSE: must include an RMSE and an explanation  (other criteria desirable)\n\n* Model evaluation: must include an evaluation discussion\n\n* Model testing : must include a discussion\n\n* Model result: must include a selection of the top 10 undervalued and overvalued  houses\n\n5. Conclusion (10 points): must include a summary of results and a discussion of things learned\n\n\n\n### Part IV\nCreate predictions for the validation data from your final model and write out to a file `prediction-validation.Rdata`\nThis should have the same format as the models in Part I and II.\n\n10 points\n\n### Class Presentations\n\nEach Group should prepare 5 slides in their Github repo:  (save as slides.pdf)\n\n* Most interesting graphic  (a picture is worth a thousand words prize!)  \n\n* Best Model (motivation, how you found it, why you think it is best)\n\n* Best Insights into predicting Sales Price.\n\n* 2 Best Houses to purchase  (and why)\n\n* Best Team Name/Graphic\n\nWe will select winners based on the above criteria and overall performance.\n\n\nFinally your repo should have: `writeup.Rmd`, `writeup.pdf`, `slides.Rmd` (and whatever output you use for the presentation) and `predict.Rdata` and `predict-validation.Rdata`.\n",
    "created" : 1493649657243.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3247119225",
    "id" : "6F9EF267",
    "lastKnownWriteTime" : 1492650985,
    "last_content_update" : 1493649659561,
    "path" : "~/STA521/Project_GGGG/Final-Data-Analysis.Rmd",
    "project_path" : null,
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}