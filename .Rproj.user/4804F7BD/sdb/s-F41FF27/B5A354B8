{
    "collab_server" : "",
    "contents" : "---\ntitle: \"project.Rmd\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## R Markdown\n\n```{r packages}\nlibrary(dplyr)\nlibrary(corrplot)\nlibrary(forcats)\nlibrary(randomForest)\nlibrary(gbm)\n```\n\n```{r load data}\nload(\"ames_train.Rdata\")\nload(\"ames_test.Rdata\")\nload(\"ames_validation.Rdata\")\nload(\"predict.Rdata\")\n```\n\n```{r}\ntrain = ames_train %>% \n  mutate(datset = \"train\")\ntest = ames_test %>%\n  mutate(datset = \"test\")\nvalid = ames_validation %>%\n  mutate(datset = \"valid\")\n\ndat = train %>% \n  rbind(., test) %>%\n  rbind(., valid)\n\nfindNA = function(col){\n  numNA = sum(is.na(col) | col == \"\")\n  type = class(col)\n  level = paste(as.character(levels(col)), collapse = \";\")\n  large_0 = sum(table(col) > 0)\n  return(c(numNA, type, level, large_0))\n}\n\ntrain_info = lapply(dat, findNA)\ntrain_info = as.data.frame(do.call(rbind, train_info), stringsAsFactors = F)\ncolnames(train_info) = c(\"numNA\", \"class\", \"level\")\ntrain_info$numNA = as.numeric(train_info$numNA)\ntrain_info$missing_ratio = train_info$numNA/nrow(ames_train)\ntrain_info$names = rownames(train_info)\n\nfeatures_drop = rownames(train_info)[train_info$missing_ratio > 0.5]\nfeatures_remain = rownames(train_info)[train_info$missing_ratio <= 0.5]\n\ndat1 = dat[, c(features_remain)]\n\n# Bsmt.Exposure\ndat1$Bsmt.Exposure[dat1$Bsmt.Exposure == \"\" &\n                     !is.na(dat1$Bsmt.Exposure)] = names(sort(table(dat1$Bsmt.Exposure), \n                                                              decreasing = T))[1]\ndat1$Mas.Vnr.Type[dat1$Mas.Vnr.Type == \"\"] = \"None\"\ndat1$Electrical[dat1$Electrical == \"\"] = names(sort(table(dat1$Electrical),\n                                                    decreasing = T))[1]\ndat1$BsmtFin.Type.2[dat1$BsmtFin.Type.2 == \"\" &\n                      !is.na(dat1$BsmtFin.Type.2)] = NA\n\ndat2 = dat1 %>%\n  dplyr::select(-Garage.Yr.Blt) %>%\n  filter(PID != 903426160) %>%\n  mutate(MS.SubClass = as.factor(MS.SubClass),\n         Lot.Frontage = ifelse(is.na(Lot.Frontage), 0, Lot.Frontage),\n         #Fireplace.Qu = fct_explicit_na(Fireplace.Qu, \"Unknown\"),\n         #Fireplace.Qu = as.numeric(factor(Fireplace.Qu, \n         #                                  levels = c(\"Unknown\", \"Po\", \"Fa\", \n         #                                             \"TA\", \"Gd\", \"Ex\"))),\n         Garage.Cond = fct_explicit_na(Garage.Cond, \"Unknown\"),\n         Garage.Cond = as.numeric(factor(Garage.Cond, \n                                         levels = c(\"Unknown\", \"Po\", \"Fa\", \n                                                    \"TA\", \"Gd\", \"Ex\"))),\n         Garage.Qual = fct_explicit_na(Garage.Qual, \"Unknown\"),\n         Garage.Qual = as.numeric(factor(Garage.Qual, \n                                         levels = c(\"Unknown\", \"Po\", \"Fa\", \n                                                    \"TA\", \"Gd\", \"Ex\"))),\n         Garage.Type = fct_explicit_na(Garage.Type, \"Unknown\"),\n         Garage.Finish = fct_explicit_na(Garage.Finish, \"Unknown\"),\n         Garage.Finish = as.numeric(factor(Garage.Finish, \n                                           levels = c(\"Unknown\", \"Unf\", \n                                                      \"RFn\", \"Fin\"))),\n         Bsmt.Qual = fct_explicit_na(Bsmt.Qual, \"Unknown\"),\n         Bsmt.Qual = as.numeric(factor(Bsmt.Qual, \n                                       levels = c(\"Unknown\", \"Po\", \"Fa\", \n                                                  \"TA\", \"Gd\", \"Ex\"))),\n         Bsmt.Cond = fct_explicit_na(Bsmt.Cond, \"Unknown\"),\n         Bsmt.Cond = as.numeric(factor(Bsmt.Cond, \n                                       levels = c(\"Unknown\", \"Po\", \"Fa\", \n                                                  \"TA\", \"Gd\", \"Ex\"))),\n         Bsmt.Exposure = fct_explicit_na(Bsmt.Exposure, \"Unknown\"),\n         Bsmt.Exposure = as.numeric(factor(Bsmt.Exposure, \n                                           levels = c(\"Unknown\", \"No\", \"Mn\", \n                                                      \"Av\", \"Gd\"))),\n         BsmtFin.Type.1 = fct_explicit_na(BsmtFin.Type.1, \"Unknown\"),\n         BsmtFin.Type.1 = as.numeric(factor(BsmtFin.Type.1, \n                                            levels = c(\"Unknown\", \"Unf\",\"LwQ\",\n                                                       \"Rec\", \"BLQ\", \n                                                       \"ALQ\", \"GLQ\"))),\n         BsmtFin.Type.2 = fct_explicit_na(BsmtFin.Type.2, \"Unknown\"),\n         BsmtFin.Type.2 = as.numeric(factor(BsmtFin.Type.2, \n                                            levels = c(\"Unknown\", \"Unf\",\"LwQ\",\n                                                       \"Rec\", \"BLQ\", \n                                                       \"ALQ\", \"GLQ\"))),\n         Mas.Vnr.Area = ifelse(is.na(Mas.Vnr.Area), 0, Mas.Vnr.Area),\n         Utilities = as.numeric(factor(Utilities, \n                                       levels = c(\"ELO\",\"NoSeWa\",\"NoSewr\",\"AllPub\"))),\n         Lot.Shape = as.numeric(factor(Lot.Shape, \n                                       levels = c(\"IR3\",\"IR2\",\"IR1\",\"Reg\"))),\n         Exter.Qual= as.numeric(factor(Exter.Qual, \n                                       levels = c(\"Po\", \"Fa\", \n                                                  \"TA\", \"Gd\", \"Ex\"))),\n         Land.Slope =  as.numeric(factor(Land.Slope, \n                                         levels = c(\"Sev\", \"Mod\",\"Gtl\"))),\n         Exter.Cond = as.numeric(factor(Exter.Cond, \n                                        levels = c(\"Po\", \"Fa\", \n                                                   \"TA\", \"Gd\", \"Ex\"))),\n         Heating.QC = as.numeric(factor(Heating.QC, \n                                        levels = c(\"Po\", \"Fa\", \n                                                   \"TA\", \"Gd\", \"Ex\"))),\n         Electrical = as.numeric(factor(Electrical, \n                                        levels = c(\"Mix\", \"FuseP\", \n                                                   \"FuseF\", \"FuseA\", \"SBrkr\"))),\n         Kitchen.Qual = as.numeric(factor(Kitchen.Qual, \n                                          levels = c(\"Po\", \"Fa\", \n                                                     \"TA\", \"Gd\", \"Ex\"))),\n         Functional = as.numeric(factor(Functional, \n                                        levels = c(\"Sal\", \"Sev\", \n                                                   \"Maj2\", \"Maj1\", \"Mod\",\n                                                   \"Min2\",\"Min1\",\"Typ\"))),\n         Paved.Drive = as.numeric(factor(Paved.Drive, \n                                         levels = c(\"N\", \"P\",\"Y\"))),\n         Bsmt.Half.Bath = ifelse(is.na(Bsmt.Half.Bath), 0, Lot.Frontage),\n         Bsmt.Full.Bath = ifelse(is.na(Bsmt.Full.Bath), 0, Lot.Frontage)\n  )\n\ndat3 = dat2 %>%\n  dplyr::select(-Condition.2)\n\ntrain_clean = dat3[dat3$datset == \"train\",] %>%\n  dplyr::select(-datset)\ntest_clean = dat3[dat3$datset == \"test\",] %>%\n  dplyr::select(-datset)\nvalidation_clean = dat3[dat3$datset == \"valid\",] %>%\n  dplyr::select(-datset)\n```\n\n```{r}\nlibrary(dplyr)\n\ndownload.file(\"http://www.openintro.org/stat/data/ames.RData\", destfile = \"ames.RData\")\nload(\"ames.RData\")\n\names_validation2 = left_join(ames_validation,ames[,c(\"PID\",\"SalePrice\")],by=\"PID\")\names_validation2 = ames_validation2[,-3]\n```\n\n\n```{r}\nsuppressMessages(library(MASS))\nsuppressMessages(library(knitr))\n\nset.seed(1)\n# colnames(train_clean)[23]   ,\"Utilities\",\"Bsmt.Full.Bath\")\n# delete_list = c(16,74,46,48,39,23,24,25)\ndelete_list = c(23,24,25,39,44,45,46)\n\ncont_var = setdiff(names(sapply(train_clean[,-delete_list],class))[sapply(train_clean[,-delete_list],class)!=\"factor\"],c(\"PID\",\"price\"))\nfactor_var = names(sapply(train_clean[,-delete_list],class))[sapply(train_clean[,-delete_list],class)==\"factor\"]\n\ninterac = paste(\"area\",paste(\":\",factor_var))\nfmla = as.formula(paste(\"log(price) ~ Neighborhood:area+\", paste(cont_var, collapse= \"+\"),\"+\",paste(factor_var,collapse = \"+\"),\"+\",paste(interac,collapse = \"+\")))\n\n\nsuppressMessages(library(glmnet))\n\nmodel2 = cv.glmnet(model.matrix(fmla,train_clean)[,-1], \n                      log(train_clean$price), \n                      alpha=1,\n                      lambda= 10^seq(4,-3,length= 1000))\nmodel2.lambda.best = model2$lambda.min\n\ntmp_coeffs <- coef(model2, s = \"lambda.min\")\ndf = data.frame(name = tmp_coeffs@Dimnames[[1]][tmp_coeffs@i+1], coefficient = tmp_coeffs@x)\n# kable(df)\n\n\nmodel2.pred = predict(model2, \n                      model.matrix(fmla,test_clean)[,-1],\n                      s = model2.lambda.best)\n\n\n# replace model1 with model2\npredictions = data.frame(fit = exp(model2.pred))\npredictions$PID = ames_test$PID\n```\n\n```{r}\nlibrary(ggplot2)\npng(height=600, width=1000, filename = \"facet.png\")\nggplot(data = train_clean, aes(x = area, y = price)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~ Neighborhood)\n```\n\n```{r}\nnsim = 50\ny_test_pred = matrix(0,nrow(test_clean),nsim)\n\nfor(i in 1:nsim){\n  model3 = cv.glmnet(model.matrix(fmla,train_clean)[,-1],\n                      log(train_clean$price),\n                      alpha=1,\n                      lambda= 10^seq(4,-3,length= 1000))\n  model3.lambda.best = model3$lambda.min\n\n\n  model3.pred = predict(model3,\n                      model.matrix(fmla,test_clean)[,-1],\n                      s = model3.lambda.best)\n  y_test_pred[,i] = model3.pred\n}\n\ny_mean = apply(exp(y_test_pred),1,mean)\ny_quantile = apply(exp(y_test_pred),1,quantile,c(0.025,0.975))\n#\n# coverage(y_quantile[1,],y_quantile[2,],test_clean$price)\n# RMSE(y_mean,test_clean$price)\npredictions$lwr = y_quantile[1,]\npredictions$upr = y_quantile[2,]\ncolnames(predictions)[1]=\"fit\"\nsave(predictions, file=\"predict.Rdata\")\n\n```\n\n```{r}\nvalidation_clean$price = 1\nmodel4.pred = predict(model2, \n                      model.matrix(fmla,validation_clean)[,-1],\n                      s = model2.lambda.best)\n\n# replace model1 with model2\nprediction_validation = data.frame(fit = exp(model4.pred))\nprediction_validation$PID = ames_validation$PID\n```\n\n```{r}\ny_test_pred2 = matrix(0,nrow(validation_clean),nsim)\n\nfor(i in 1:nsim){\n  model3 = cv.glmnet(model.matrix(fmla,train_clean)[,-1],\n                      log(train_clean$price),\n                      alpha=1,\n                      lambda= 10^seq(4,-3,length= 1000))\n  model3.lambda.best = model3$lambda.min\n\n\n  model3.pred = predict(model3,\n                      model.matrix(fmla,validation_clean)[,-1],\n                      s = model3.lambda.best)\n  y_test_pred2[,i] = model3.pred\n}\n\ny_mean2 = apply(exp(y_test_pred2),1,mean)\ny_quantile2 = apply(exp(y_test_pred2),1,quantile,c(0.025,0.975))\n\nprediction_validation$lwr = y_quantile2[1,]\nprediction_validation$upr = y_quantile2[2,]\ncolnames(prediction_validation)[1]=\"fit\"\n```\n\n```{r create }\n# name dataframe as predictions! DO NOT CHANGE\npredictions = data.frame(PID = ames_validation$PID)\npredictions$fit = exp(model4.pred)\npredictions$lwr = y_quantile2[1,]\npredictions$upr = y_quantile2[2,]\nsave(predictions, file=\"predict-validation.Rdata\")\n```\n\n```{r functions}\ncheck = function(pred, true_value){\n  return(data.frame(RMSE = RMSE(pred[,1],true_value),\n                    BIAS = BIAS(pred[,1],true_value),\n                    maxDeviation = maxDeviation(pred[,1],true_value),\n                    MeanAbsDeviation = MeanAbsDeviation(pred[,1],true_value),\n                    Coverage = coverage(pred[,2], pred[,3], true_value)))\n}\nRMSE = function(y,pred) {\n  rmse = sqrt(mean((y-pred)^2))\n  return(rmse)\n}\n\nBIAS = function(pred, true_value){\n  return(mean(pred-true_value))\n}\nmaxDeviation = function(pred, true_value){\n  return(max(abs(pred-true_value)))\n}\nMeanAbsDeviation = function(pred, true_value){\n  return(mean(abs(pred-true_value)))\n}\ncoverage = function(lwr,upr,true_value){\n  mean(lwr<true_value & true_value<upr)\n}\n```\n\n```{r distribution of price, echo=FALSE}\npng(width=900, pointsize=15, filename = \"price.png\")\npar(mfrow = c(1,2))\nhist(train_clean$price, breaks = 30)\nhist(log(train_clean$price), breaks = 30)\n```\n\n```{r correlation between variables, echo=FALSE}\nisNums = sapply(train_clean, is.numeric)\nM = cor(train_clean[, isNums])\npng(height=1200, width=1500, pointsize=15, filename = \"corr.png\")\ncorrplot(M, method=\"circle\", insig = \"blank\", tl.cex = 1/par(\"cex\"),\n    cl.cex = 1/par(\"cex\"), addCoefasPercent = TRUE)\n```\n\n```{r variable importance}\nmodel_rf = randomForest(log(price) ~., data = train_clean, mtry = 9, importance = T)\npng(width=900, pointsize=15, filename = \"rf_varImportance.png\")\nvarImpPlot(model_rf)\n\nmodel_boosting = gbm(log(price) ~., data = train_clean, distribution = \"gaussian\", n.trees = 30000,\n                     interaction.depth = 4)\npng(pointsize=15, filename = \"boosting_varImportance.png\")\nsummary(model_boosting)\n```\n\n```{r ols with BIC}\nmodel_ols = lm(log(price) ~ . , \n               data = train_clean[-c(168,183,462),])\nsummary(model_ols)\n\nmodel_ols_bic = step(model_ols, k = log(nrow(train_clean)))\nsummary(model_ols_bic)\n\npredict_ols_bic_train = exp(model_ols_bic$fitted.values)\nRMSE(predict_ols_bic_train, train_clean[-c(168,183,462),]$price)\n\npredict_ols_bic = predict(model_ols_bic, newdata = test_clean, interval = \"predict\")\npredict_ols_bic = exp(predict_ols_bic)\ncheck(predict_ols_bic, test_clean$price)\nplot(test_clean$price, predict_ols_bic[,1], )\nabline(a=0, b=1)\n\nplot(model_ols_bic)\ntermplot(model = model_ols_bic, partial.resid = T, se = T, rug = T, smooth = panel.smooth)\n```\n\n```{r validation data}\npredict_ols_bic = predict(model_ols_bic, newdata = validation_clean, interval = \"predict\")\npredict_ols_bic = exp(predict_ols_bic)\n\ncheck(predict_ols_bic, ames_validation2$SalePrice)\nplot(ames_validation2$SalePrice, predict_ols_bic[,1], )\nabline(a=0, b=1)\n```\n\n```{r ols trans x and y}\nmodel_ols_trans = lm(log(price) ~ \n                       area + log(Lot.Area + 1) + Neighborhood + Bldg.Type + \n                       Overall.Qual + Overall.Cond + \n                       Year.Built + \n                       #Year.Remod.Add + \n                       Bsmt.Exposure + BsmtFin.SF.1 + BsmtFin.SF.2 + Bsmt.Unf.SF +\n                       Central.Air + \n                       Kitchen.Qual + Functional + \n                       Fireplaces + \n                       Garage.Cars + \n                       #Garage.Area + \n                       Paved.Drive + Open.Porch.SF, \n                       #+ log(Enclosed.Porch + 1) + log(Screen.Porch + 1), \n                       data = train_clean[-c(168,183,462),])\nplot(model_ols_trans)\n\npredict_ols_trans_train = exp(model_ols_trans$fitted.values)\nRMSE(predict_ols_trans_train, train_clean[-c(168,183,462),]$price)\n\npredict_ols_trans = predict(model_ols_trans, newdata = test_clean, interval = \"predict\")\npredict_ols_trans = exp(predict_ols_trans)\ncheck(predict_ols_trans, test_clean$price)\n\nplot(test_clean$price, predict_ols_trans[,1] )\nabline(a=0, b=1)\n\nplot(model_ols_trans)\ntermplot(model = model_ols_trans, partial.resid = T, se = T, rug = T, smooth = panel.smooth)\n```\n\n```{r validation data}\npredict_ols_trans = predict(model_ols_trans, newdata = validation_clean, interval = \"predict\")\npredict_ols_trans = exp(predict_ols_trans)\ncheck(predict_ols_trans, ames_validation2$SalePrice)\n\nplot(ames_validation2$SalePrice, predict_ols_trans[,1], )\nabline(a=0, b=1)\n```\n\n```{r}\nmodel_ols_trans = lm(log(price) ~ \n                       area + log(Lot.Area + 1) + Neighborhood + Bldg.Type + \n                       Overall.Qual + Overall.Cond + \n                       Year.Built + \n                       #Year.Remod.Add + \n                       Bsmt.Exposure + BsmtFin.SF.1 + BsmtFin.SF.2 + Bsmt.Unf.SF +\n                       Central.Air + \n                       Kitchen.Qual + Functional + \n                       Fireplaces + \n                       Garage.Cars + \n                       #Garage.Area + \n                       Paved.Drive + Open.Porch.SF, \n                       #+ log(Enclosed.Porch + 1) + log(Screen.Porch + 1), \n                       data = )\n```\n\n```{r poisson}\nlibrary(MASS)\n\n#delete columns with colinearity and new levels\ndelete_list = c(16,74,46,48,39,23,24,25)\n\nmodel1.poi =glm(price ~ .-PID, \n              data = train_clean[,-delete_list],family=\"poisson\")\n\nmodel_poi_bic = step(model1.poi, k = log(nrow(train_clean)),trace = F)\n\ny_poi_train = predict(model1.poi,newdata = train_clean)\ncheck(exp(y_poi_train),train_clean$price)\n\ny_poi_test = predict(model1.poi,newdata = test_clean)\ncheck(exp(y_poi_test),test_clean$price)\n\ny_poi_validation = predict(model1.poi,newdata = validation_clean)\ncheck(exp(y_poi_validation),ames_validation2$SalePrice)\n```\n\n```{r boosting}\nlibrary(gbm)\nmodel_boosting = gbm(exp(price) ~ area + log(Lot.Area + 1) + Neighborhood + Bldg.Type + Overall.Qual +\n                       Overall.Cond + Year.Built + \n                       #Year.Remod.Add + \n                       Bsmt.Exposure + BsmtFin.SF.1 + \n                       BsmtFin.SF.2 + Bsmt.Unf.SF + Central.Air + Kitchen.Qual + Functional + \n                       Fireplaces + Garage.Cars + Garage.Area + Paved.Drive + Open.Porch.SF ,\n                       #log(Enclosed.Porch + 1) + log(Screen.Porch + 1), , \n                     data = train_clean[-c(168,183,462),], \n                     distribution = \"gaussian\",\n                     n.trees = 30000, \n                     interaction.depth = 4)\nsummary(model_boosting, plotit = F)\n\npredict_boosting = predict(model_boosting, newdata = test_clean, n.trees = 30000)\npredict_boosting = cbind(predict_boosting, predict_boosting_lower, predict_boosting_upper)\npredict_boosting = exp(predict_boosting)\n# how to compute prediction intervals for boosting\nrmse_boosting = RMSE(predict_boosting, test_clean$price)\nrmse_boosting\ncheck(predict_boosting, test_clean$price)\nplot(test_clean$price, predict_boosting, )\nabline(a=0, b=1)\n```\n\n```{r validation data}\npredict_boosting = predict(model_boosting, newdata = validation_clean, n.trees = 30000)\npredict_boosting = cbind(predict_boosting, predict_boosting_lower, predict_boosting_upper)\npredict_boosting = exp(predict_boosting)\nrmse_boosting = RMSE(predict_boosting, ames_validation2$SalePrice)\nrmse_boosting\ncheck(predict_boosting, ames_validation2$SalePrice)\nplot(ames_validation2$SalePrice, predict_boosting )\nabline(a=0, b=1)\n```\n\n```{r save}\n# name dataframe as predictions! DO NOT CHANGE\npredictions = NULL\npredictions$fit = predict_boosting[,1]\npredictions$lwr = predict_boosting[,2]\npredictions$upr = predict_boosting[,3]\npredictions$PID = ames_test$PID\npredictions = as.data.frame(predictions)\nsave(predictions, file=\"predict.Rdata\")\n```\n\n",
    "created" : 1493649648507.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3785375450",
    "id" : "B5A354B8",
    "lastKnownWriteTime" : 1493611754,
    "last_content_update" : 1493611754,
    "path" : "~/STA521/Project_GGGG/project.rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}